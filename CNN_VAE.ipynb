{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_VAE.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMqUU0Rntcmhj3BqHuWSRSu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehdihosseinimoghadam/Pytorch-Tutorial/blob/main/CNN_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cJUPAsySVVhZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchaudio.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super(ConvBlock, self).__init__()\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.Conv = nn.Sequential(\n",
        "        nn.Conv2d(self.in_channels,\n",
        "                  self.out_channels,\n",
        "                  4,\n",
        "                  2,\n",
        "                  1),\n",
        "        nn.BatchNorm2d(self.out_channels),\n",
        "        nn.LeakyReLU()          \n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.Conv(x)  \n",
        "\n",
        "\n",
        "\n",
        "class TransConvBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super(TransConvBlock, self).__init__()\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.Conv = nn.Sequential(\n",
        "        nn.ConvTranspose2d(self.in_channels,\n",
        "                  self.out_channels,\n",
        "                  4,\n",
        "                  2,\n",
        "                  1),\n",
        "        nn.BatchNorm2d(self.out_channels),\n",
        "        nn.LeakyReLU()          \n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.Conv(x)  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Encode(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, latent_dim, filter_num_list=[2, 4, 8]):\n",
        "    super(Encode, self).__init__()\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.latent_dim = latent_dim\n",
        "    self.filter_num_list = filter_num_list\n",
        "\n",
        "    self.Conv = nn.Sequential(\n",
        "        ConvBlock(self.in_channels, self.out_channels),\n",
        "        ConvBlock(self.out_channels, self.out_channels * self.filter_num_list[0]),\n",
        "        ConvBlock(self.out_channels * self.filter_num_list[0], self.out_channels * self.filter_num_list[1]),\n",
        "        ConvBlock(self.out_channels * self.filter_num_list[1], self.out_channels * self.filter_num_list[2])\n",
        "    )\n",
        "\n",
        "    self.fc = nn.Linear(80 * 2 * 2, self.latent_dim)\n",
        "    self.mu = nn.Linear(self.latent_dim, self.latent_dim)\n",
        "    self.logvar = nn.Linear(self.latent_dim, self.latent_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.Conv(x)\n",
        "    print(x.shape)\n",
        "    x = x.reshape(-1, 80 * 2 * 2)\n",
        "    x = self.fc(x)\n",
        "    mu = self.mu(x)\n",
        "    logvar = self.logvar(x)\n",
        "    return mu, logvar\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, latent_dim, filter_num_list=[2,4,8]):\n",
        "    super(Decoder, self).__init__() \n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.latent_dim = latent_dim\n",
        "    self.filter_num_list = filter_num_list \n",
        "\n",
        "    self.DeConve = nn.Sequential(\n",
        "        TransConvBlock(self.out_channels* self.filter_num_list[2] , self.out_channels * self.filter_num_list[1]),\n",
        "        TransConvBlock(self.out_channels * self.filter_num_list[1], self.out_channels * self.filter_num_list[0]),\n",
        "        TransConvBlock(self.out_channels * self.filter_num_list[0], self.out_channels ),\n",
        "        TransConvBlock(self.out_channels , self.in_channels)\n",
        "    )\n",
        "    self.fc = nn.Linear(latent_dim, 1*80*2*2)\n",
        "\n",
        "\n",
        "  def reparameterezation(self, mu, logvar):\n",
        "    eps = torch.randn_like(logvar)\n",
        "    z = mu + eps*torch.exp(.5*logvar) \n",
        "    return z\n",
        "\n",
        "\n",
        "  def forward(self, mu, logvar): \n",
        "    z = self.reparameterezation(mu, logvar)\n",
        "    print(z.shape)\n",
        "    z = nn.functional.relu(z)\n",
        "    print(z.shape)\n",
        "    x = nn.functional.relu(self.fc(z))\n",
        "    print(x.shape)\n",
        "    x = x.reshape(-1, 80,2,2)\n",
        "    x = self.DeConve(x)\n",
        "    return x, mu, logvar\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class VAE(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, latent_dim, filter_num_list=[2,4,8]):\n",
        "    super(VAE, self).__init()\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.latent_dim = latent_dim\n",
        "    self.filter_num_list = filter_num_list\n",
        "\n",
        "    self.Encodee = Encode(in_channels = 1, out_channels = 10, latent_dim = self.filter_num_list)\n",
        "    self.Decoder = Decoder(in_channels = 1, out_channels = 10, latent_dim = self.filter_num_list)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kb7cMcCGW6hL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.rand(1,32,32).unsqueeze(0)\n",
        "En = Encode(in_channels = self.in_channels , out_channels = self.out_channels, latent_dim = 100)\n",
        "En(a)[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzcyajuAevl4",
        "outputId": "d268ae9c-6e57-4f01-fe08-53635cee1ba8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 80, 2, 2])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = torch.rand(1,100)\n",
        "De = Decoder(in_channels = 1, out_channels = 10, latent_dim = 100)\n",
        "x, mu, logvar = De(b,b)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pmxml9z7fb3N",
        "outputId": "a1fd6110-4eeb-41a8-92e4-992e1363e263"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 100])\n",
            "torch.Size([1, 100])\n",
            "torch.Size([1, 320])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.datasets as Datasets\n",
        "import torchvision.transforms as transform\n",
        "from torch.utils.data import DataLoader "
      ],
      "metadata": {
        "id": "6AG4f4UuZqhR"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trans = transform.Compose([\n",
        "                           transform.Resize((32,32)),\n",
        "                           transform.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "j92YadGnlODu"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = Datasets.MNIST(root=\"/\", train=True, transform= trans, download=True)\n",
        "test_data = Datasets.MNIST(root=\"/\", train=False, transform= trans, download=True)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=16, shuffle=True)"
      ],
      "metadata": {
        "id": "u7YwvT0YkHFG"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "H_4T7fHlnEXv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}