{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_VAE.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNWS5zpudf5vnwFjYblLS6C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehdihosseinimoghadam/Pytorch-Tutorial/blob/main/CNN_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cJUPAsySVVhZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchaudio.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super(ConvBlock, self).__init__()\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.Conv = nn.Sequential(\n",
        "        nn.Conv2d(self.in_channels,\n",
        "                  self.out_channels,\n",
        "                  4,\n",
        "                  2,\n",
        "                  1),\n",
        "        nn.BatchNorm2d(self.out_channels),\n",
        "        nn.LeakyReLU()          \n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.Conv(x)  \n",
        "\n",
        "\n",
        "\n",
        "class TransConvBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super(TransConvBlock, self).__init__()\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.Conv = nn.Sequential(\n",
        "        nn.ConvTranspose2d(self.in_channels,\n",
        "                  self.out_channels,\n",
        "                  4,\n",
        "                  2,\n",
        "                  1),\n",
        "        nn.BatchNorm2d(self.out_channels),\n",
        "        nn.LeakyReLU()          \n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.Conv(x)  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Encode(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, latent_dim, filter_num_list=[2, 4, 8]):\n",
        "    super(Encode, self).__init__()\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.latent_dim = latent_dim\n",
        "    self.filter_num_list = filter_num_list\n",
        "\n",
        "    self.Conv = nn.Sequential(\n",
        "        ConvBlock(self.in_channels, self.out_channels),\n",
        "        ConvBlock(self.out_channels, self.out_channels * self.filter_num_list[0]),\n",
        "        ConvBlock(self.out_channels * self.filter_num_list[0], self.out_channels * self.filter_num_list[1]),\n",
        "        ConvBlock(self.out_channels * self.filter_num_list[1], self.out_channels * self.filter_num_list[2])\n",
        "    )\n",
        "\n",
        "    self.fc = nn.Linear(80 * 2 * 2, self.latent_dim)\n",
        "    self.mu = nn.Linear(self.latent_dim, self.latent_dim)\n",
        "    self.logvar = nn.Linear(self.latent_dim, self.latent_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.Conv(x)\n",
        "    print(x.shape)\n",
        "    x = x.reshape(-1, 80 * 2 * 2)\n",
        "    x = self.fc(x)\n",
        "    mu = self.mu(x)\n",
        "    logvar = self.logvar(x)\n",
        "    return mu, logvar\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, latent_dim, filter_num_list=[2,4,8]):\n",
        "    super(Decoder, self).__init__() \n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.latent_dim = latent_dim\n",
        "    self.filter_num_list = filter_num_list \n",
        "\n",
        "    self.DeConve = nn.Sequential(\n",
        "        TransConvBlock(self.out_channels* self.filter_num_list[2] , self.out_channels * self.filter_num_list[1]),\n",
        "        TransConvBlock(self.out_channels * self.filter_num_list[1], self.out_channels * self.filter_num_list[0]),\n",
        "        TransConvBlock(self.out_channels * self.filter_num_list[0], self.out_channels ),\n",
        "        TransConvBlock(self.out_channels , self.in_channels)\n",
        "    )\n",
        "    self.fc = nn.Linear(latent_dim, 1*80*2*2)\n",
        "\n",
        "\n",
        "  def reparameterezation(self, mu, logvar):\n",
        "    eps = torch.randn_like(logvar)\n",
        "    z = mu + eps*torch.exp(.5*logvar) \n",
        "    return z\n",
        "\n",
        "\n",
        "  def forward(self, mu, logvar): \n",
        "    z = self.reparameterezation(mu, logvar)\n",
        "    print(z.shape)\n",
        "    z = nn.functional.relu(z)\n",
        "    print(z.shape)\n",
        "    x = nn.functional.relu(self.fc(z))\n",
        "    print(x.shape)\n",
        "    x = x.reshape(-1, 80,2,2)\n",
        "    x = self.DeConve(x)\n",
        "    return x, mu, logvar\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class VAE(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, latent_dim, filter_num_list=[2,4,8]):\n",
        "    super(VAE, self).__init__()\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.latent_dim = latent_dim\n",
        "    self.filter_num_list = filter_num_list\n",
        "\n",
        "    self.Encoder = Encode(self.in_channels,  self.out_channels, self.latent_dim)\n",
        "    self.Decoder = Decoder(self.in_channels, self.out_channels, self.latent_dim)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    mu, logvar = self.Encoder(x)\n",
        "    x, mu, logvar = self.Decoder(mu, logvar)\n",
        "    return x, mu, logvar"
      ],
      "metadata": {
        "id": "kb7cMcCGW6hL"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.rand(1,32,32).unsqueeze(0)\n",
        "En = Encode(in_channels = self.in_channels , out_channels = self.out_channels, latent_dim = 100)\n",
        "En(a)[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "UzcyajuAevl4",
        "outputId": "914c3643-37f0-4ce3-f6c6-9271c49a15e8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-d051951606bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mEn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_channels\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mEn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = torch.rand(1,100)\n",
        "De = Decoder(in_channels = 1, out_channels = 10, latent_dim = 100)\n",
        "x, mu, logvar = De(b,b)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pmxml9z7fb3N",
        "outputId": "132e7f5f-bdc5-491b-9818-72dace970242"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 100])\n",
            "torch.Size([1, 100])\n",
            "torch.Size([1, 320])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vae = VAE(in_channels = 1, out_channels = 10, latent_dim = 100)\n",
        "vae(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4lpGvySrfj-",
        "outputId": "48c387c5-5d44-47ad-9f3f-0b3403cc7d8b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "torch.Size([1, 80, 2, 2])\n",
            "2\n",
            "torch.Size([1, 100])\n",
            "torch.Size([1, 100])\n",
            "torch.Size([1, 320])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[[-4.8670e-03,  1.4876e-01,  8.9300e-02,  ..., -2.5375e-03,\n",
              "            -3.0995e-03, -5.4577e-03],\n",
              "           [-4.9363e-03, -3.4678e-03, -1.3821e-02,  ..., -2.4478e-03,\n",
              "             6.6602e-02, -5.3227e-03],\n",
              "           [-5.1893e-03,  7.1839e-01,  6.1820e-01,  ...,  2.1360e-01,\n",
              "             1.7043e-01, -6.7877e-03],\n",
              "           ...,\n",
              "           [-8.1936e-03, -8.1051e-04, -2.3900e-03,  ..., -4.0086e-03,\n",
              "            -2.1950e-03, -2.5957e-03],\n",
              "           [-2.2080e-03,  1.4105e+00,  2.3565e-01,  ...,  8.0272e-02,\n",
              "            -3.5431e-04, -4.1178e-03],\n",
              "           [-2.8191e-03, -4.2940e-03, -5.9128e-03,  ..., -5.4708e-03,\n",
              "            -1.4982e-03, -2.8085e-03]]]], grad_fn=<LeakyReluBackward0>),\n",
              " tensor([[ 0.1519, -0.4500,  0.0620, -0.0200,  0.0613,  0.2973,  0.0926,  0.2685,\n",
              "           0.0106,  0.2134,  0.4791, -0.5707, -0.0932,  0.2887,  0.0886,  0.1570,\n",
              "          -0.0405, -0.0912, -0.0115,  0.3044, -0.0906, -0.5512,  0.1918,  0.2910,\n",
              "           0.1034, -0.4667,  0.2199,  0.1940,  0.3106, -0.4407,  0.0373, -0.1225,\n",
              "          -0.0770, -0.1096, -0.1039, -0.3238,  0.2161,  0.0819,  0.0028, -0.1104,\n",
              "          -0.0023,  0.4761, -0.2408,  0.2431,  0.0573,  0.4066,  0.3926, -0.0100,\n",
              "           0.5951,  0.2465,  0.3329,  0.1693, -0.1347,  0.1057, -0.1694,  0.3240,\n",
              "           0.2066, -0.2528,  0.0656, -0.1744,  0.1385,  0.3015, -0.0120, -0.2687,\n",
              "          -0.3489, -0.0277,  0.1876, -0.1881,  0.2454, -0.1690, -0.0274, -0.1122,\n",
              "           0.2577,  0.0471, -0.3005, -0.2603, -0.3379,  0.0242,  0.0968, -0.0212,\n",
              "          -0.3802, -0.1933,  0.3943, -0.0567, -0.0266, -0.4424, -0.1265,  0.2393,\n",
              "           0.1477, -0.0714,  0.3883, -0.0967,  0.1176, -0.1150, -0.2417, -0.3667,\n",
              "           0.0145, -0.0405, -0.1450, -0.2782]], grad_fn=<AddmmBackward0>),\n",
              " tensor([[-0.1853, -0.4364,  0.3926,  0.0704,  0.0462,  0.1847, -0.0592,  0.5056,\n",
              "           0.0252,  0.3929, -0.2062, -0.2352, -0.4006, -0.5219, -0.0269,  0.2233,\n",
              "           0.2686,  0.1304, -0.2608,  0.0438,  0.2745, -0.2536, -0.1766, -0.2810,\n",
              "          -0.2459, -0.1049, -0.4091,  0.0529,  0.0380,  0.1583,  0.0791, -0.0117,\n",
              "          -0.1028,  0.0501,  0.0924, -0.2620,  0.3543,  0.0371, -0.3330,  0.0362,\n",
              "          -0.2064, -0.2407, -0.4385,  0.2614,  0.3665,  0.0155,  0.1369,  0.1560,\n",
              "          -0.4283,  0.3079,  0.0566, -0.0733,  0.4149,  0.0838, -0.1854,  0.0497,\n",
              "           0.2361,  0.4236, -0.0467,  0.5116,  0.2062,  0.0044,  0.5331,  0.0962,\n",
              "           0.0833,  0.1200,  0.1212, -0.1204,  0.3243,  0.3487, -0.3621, -0.3261,\n",
              "          -0.1378, -0.4409,  0.2988,  0.1356,  0.0987,  0.1201,  0.1439,  0.1973,\n",
              "           0.0572, -0.2373,  0.2476,  0.3332,  0.5146, -0.0264,  0.0088,  0.0024,\n",
              "           0.3712,  0.1255,  0.3181, -0.3535, -0.3038, -0.0882,  0.1157, -0.2279,\n",
              "          -0.1826, -0.3350, -0.1279, -0.0063]], grad_fn=<AddmmBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.datasets as Datasets\n",
        "import torchvision.transforms as transform\n",
        "from torch.utils.data import DataLoader "
      ],
      "metadata": {
        "id": "6AG4f4UuZqhR"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trans = transform.Compose([\n",
        "                           transform.Resize((32,32)),\n",
        "                           transform.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "j92YadGnlODu"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = Datasets.MNIST(root=\"/\", train=True, transform= trans, download=True)\n",
        "test_data = Datasets.MNIST(root=\"/\", train=False, transform= trans, download=True)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=16, shuffle=True)"
      ],
      "metadata": {
        "id": "u7YwvT0YkHFG"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "H_4T7fHlnEXv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}